import numpy as np
import pandas as pd
import pickle as pkl
from scipy.sparse import coo_matrix
from sklearn.feature_extraction.text import TfidfTransformer

def feature_concat(*F_list, normal_col=False):
    """
    Concatenate multiple modality feature. If the dimension of a feature matrix is more than two,
    the function will reduce it into two dimension(using the last dimension as the feature dimension,
    the other dimension will be fused as the object dimension)
    :param F_list: Feature matrix list
    :param normal_col: normalize each column of the feature
    :return: Fused feature matrix
    """
    features = None
    for f in F_list:
        if f is not None and f != []:
            # deal with the dimension that more than two
            if len(f.shape) > 2:
                f = f.reshape(-1, f.shape[-1])
            # normal each column
            if normal_col:
                f_max = np.max(np.abs(f), axis=0)
                f = f / f_max
            # facing the first feature matrix appended to fused feature matrix
            if features is None:
                features = f
            else:
                features = np.hstack((features, f))
    if normal_col:
        features_max = np.max(np.abs(features), axis=0)
        features = features / features_max
    return features


def hyperedge_concat(*H_list):
    """
    Concatenate hyperedge group in H_list
    :param H_list: Hyperedge groups which contain two or more hypergraph incidence matrix
    :return: Fused hypergraph incidence matrix
    """
    H = None
    for h in H_list:
        if h is not None and h != []:
            # for the first H appended to fused hypergraph incidence matrix
            if H is None:
                H = h
            else:
                if type(h) != list:
                    H = np.hstack((H, h))
                else:
                    tmp = []
                    for a, b in zip(H, h):
                        tmp.append(np.hstack((a, b)))
                    H = tmp
    return H


def generate_G_from_H(H, variable_weight=False):
    """
    calculate G from hypgraph incidence matrix H
    :param H: hypergraph incidence matrix H
    :param variable_weight: whether the weight of hyperedge is variable
    :return: G
    """
    if type(H) != list:
        return _generate_G_from_H(H, variable_weight)
    else:
        G = []
        for sub_H in H:
            G.append(generate_G_from_H(sub_H, variable_weight))
        return G


def _generate_G_from_H(H, variable_weight=False):
    """
    calculate G from hypgraph incidence matrix H
    :param H: hypergraph incidence matrix H
    :param variable_weight: whether the weight of hyperedge is variable, this is likely useful to penalize very large pathways
    :return: G
    """
    H = np.array(H, dtype=float)
    n_edge = H.shape[1]
    # the weight of the hyperedge
    W = np.ones(n_edge)
    # the degree of the node
    DV = np.sum(H * W, axis=1)
    # the degree of the hyperedge
    DE = np.sum(H, axis=0)

    invDE = np.mat(np.diag(np.power(DE, -1)))
    DV2 = np.mat(np.diag(np.power(DV, -0.5)))
    W = np.mat(np.diag(W))
    H = np.mat(H)
    HT = H.T

    if variable_weight:
        DV2_H = DV2 * H
        invDE_HT_DV2 = invDE * HT * DV2
        return DV2_H, W, invDE_HT_DV2
    else:
        G = DV2 * H * W * invDE * HT * DV2
        return G



def construct_Hexp(fn_H, fn_m, dataset='MC3'):
    """
    init multi-scale hypergraph Vertex-Edge matrix from sparse tensor file
the dataset_gene_pathway.hg file is generated by the gene_pathway_group.R file fro the respective dataset
    :param spt: sparse tensor file
    :return: N_genes x M_hyperedge (pathways)
    """
    # m is patient x gene matrix, y is label
    f = open(fn_m, 'rb')
    if dataset == 'MC3':
        [m, cf, y] = pkl.load(f)
        # get unique label list
        y, yuniques = pd.factorize(y, sort=True)
        idx1 = m.index.tolist()
        # idx1[0] = '0003' # done: need to pre-process and re-save tcga data
        idx1 = ['p|' + x for x in idx1] # p| distinguishes pt node labels
        m.index = idx1
        cf.index = idx1
    elif dataset == 'disgenet':
        [m, y] = pkl.load(f)
        yuniques = y.columns.values
        y = y.values
    else:
        sys.exit(f'unrecognized dataset {dataset}')        
    f.close()

    # H is the gene hypergraph, pathway as hyperedge
    H = pd.read_csv(fn_H, index_col=0)
    
    # Hexp is the patient gene hypergraph, pathway and patient-mutation profile as hyperedge
    Hexp = pd.DataFrame(np.zeros((H.shape[0]+m.shape[0],
                                  H.shape[1]+m.shape[0])),
                        index = H.index.tolist()+m.index.tolist(),
                        columns = H.columns.tolist()+m.index.tolist(),
                        dtype=float)
    Hexp.loc[H.index, H.columns] = H
    Hexp.loc[m.index, m.index] = np.identity(len(m.index))
    Hexp.loc[H.index, m.index] = m.T # [H.index, m.index]

    gene_idx = slice(0, len(H.index), 1)
    subj_idx = slice(len(H.index), len(Hexp.index), 1) # can be pt or dx
    if dataset == 'MC3':
        return Hexp, gene_idx, subj_idx, cf, y, yuniques
    elif dataset == 'disgenet':
        return Hexp, gene_idx, subj_idx, y, yuniques

def construct_Hexp_inductive(fn_H, m, tfidf = False):
    """
    init multi-scale hypergraph Vertex-Edge matrix from sparse tensor file
the dataset_gene_pathway.hg file is generated by the gene_pathway_group.R file fro the respective dataset
    :param 
    fn_H: pathway hyperedge file
    m: training matrix
    :return: N_genes x M_hyperedge (pathways)
    """
    # H is the gene hypergraph, pathway as hyperedge
    H = pd.read_csv(fn_H, index_col=0).astype('float')
    
    # Hexp adds the training subject-mutation profile as hyperedge
    Hexp = pd.DataFrame(np.zeros((H.shape[0],
                                  H.shape[1]+m.shape[0])),
                        index = H.index.tolist(),
                        columns = H.columns.tolist()+m.index.tolist(),
                        dtype=float)
    Hexp.loc[H.index, H.columns] = H
    Hexp.loc[H.index, m.index] = m.T # [H.index, m.index]

    pathway_idx = slice(0, len(H.index), 1)
    subj_idx = slice(len(H.index), len(Hexp.index), 1)
    if tfidf:
        tx = TfidfTransformer()
        Hexp = tx.fit_transform(Hexp).todense()
    return Hexp, pathway_idx, subj_idx

def construct_Hexp_KNN_inductive(fn_H, m, k_neig=3, is_probH=False, m_prob=1):
    """
    construct hypregraph incidence matrix from hypergraph node distance matrix
    :param corr_mat: node distance matrix
    :param k_neig: K nearest neighbor
    :param is_probH: prob Vertex-Edge matrix or binary
    :param m_prob: prob
    :return: N_object X N_hyperedge
    """
    # H is the gene hypergraph, pathway as hyperedge
    H = pd.read_csv(fn_H, index_col=0).astype('float')
    
    # Hexp adds the gene KNNs from training subject-mutation profile as hyperedge
    genes = m.columns.tolist()
    Hexp = pd.DataFrame(np.zeros((H.shape[0],
                                  H.shape[1]+m.shape[1])),
                        index = H.index.tolist(),
                        columns = H.columns.tolist() + genes,
                        dtype=float)
    Hexp.loc[H.index, H.columns] = H
    
    corr_mat = np.corrcoef(m, rowvar=False)
    corr_mat = np.nan_to_num(corr_mat)
    n_obj = corr_mat.shape[0]
    # construct hyperedge from the central feature space of each node
    n_edge = n_obj

    pathway_idx = slice(0, len(H.index), 1)
    knn_idx = slice(len(H.index), len(Hexp.index), 1)
    
    for center_idx in range(n_obj):
        corr_vec = corr_mat[center_idx]
        nearest_idx = np.array(np.argsort(corr_vec)).squeeze()
        avg_dis = np.average(corr_vec)
        if not np.any(nearest_idx[-k_neig:] == center_idx):
            nearest_idx[-k_neig] = center_idx

        for node_idx in nearest_idx[-k_neig:]:
            if is_probH:
                Hexp.loc[genes[node_idx], genes[center_idx]] = np.exp(-corr_vec[0, node_idx] ** 2 / (m_prob * avg_dis) ** 2)
            else:
                Hexp.loc[genes[node_idx], genes[center_idx]] = 1.0

    return Hexp, pathway_idx, knn_idx


def construct_H(fn_H, tfidf = False):
    """
    init multi-scale hypergraph Vertex-Edge matrix from sparse tensor file
the dataset_gene_pathway.hg file is generated by the gene_pathway_group.R file fro the respective dataset
    :param spt: sparse tensor file
    :return: N_genes x M_hyperedge (pathways)
    """
    # H is the gene hypergraph, pathway as hyperedge
    H = pd.read_csv(fn_H, index_col=0).astype('float')
    if tfidf:
        tx = TfidfTransformer()
        H = tx.fit_transform(H).todense()
    return H
